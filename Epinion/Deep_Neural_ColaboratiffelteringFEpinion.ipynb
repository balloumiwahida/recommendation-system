{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model-Neural-CFEpinion.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdLmldJ4Zknk",
        "colab_type": "text"
      },
      "source": [
        "## Deep Neural CF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_1dlqDGHwoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-wj6P2UH1Id",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwRIY6NfamCo",
        "colab_type": "text"
      },
      "source": [
        "### Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbrmDOBlH_aj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cd37c050-4d2d-4a71-ee83-87d84eb89bfb"
      },
      "source": [
        "df_rating=pd.read_csv('/content/ratings_data.txt',encoding = \"ISO-8859-1\",delim_whitespace = True, header=None, dtype=object,names = ['userid','itemid','rating']) \n",
        "df_rating.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userid</th>\n",
              "      <th>itemid</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>101</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>102</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>103</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>104</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  userid itemid rating\n",
              "0      1    101      5\n",
              "1      1    102      3\n",
              "2      1     10      3\n",
              "3      1    103      5\n",
              "4      1    104      2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTjJh8lmIW-m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cfdb907e-ba1a-44db-839a-87d342e89f05"
      },
      "source": [
        "pip install sklearn"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxC753NMIdsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iRqm6mdMIjcS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_user_item(df, user_col, item_col, rating_col):\n",
        "    \"\"\"Function to encode users and items\n",
        "    \n",
        "    Params:     \n",
        "        df (pd.DataFrame): Pandas data frame to be used.\n",
        "        user_col (string): Name of the user column.\n",
        "        item_col (string): Name of the item column.\n",
        "        rating_col (string): Name of the rating column.\n",
        "        timestamp_col (string): Name of the timestamp column.\n",
        "    \n",
        "    Returns: \n",
        "        encoded_df (pd.DataFrame): Modifed dataframe with the users and items index\n",
        "    \"\"\"\n",
        "    \n",
        "    encoded_df = df.copy()\n",
        "    \n",
        "    user_encoder = LabelEncoder()\n",
        "    user_encoder.fit(encoded_df[user_col].values)\n",
        "    n_users = len(user_encoder.classes_)\n",
        "    \n",
        "    item_encoder = LabelEncoder()\n",
        "    item_encoder.fit(encoded_df[item_col].values)\n",
        "    n_items = len(item_encoder.classes_)\n",
        "\n",
        "    rating_encoder = LabelEncoder()\n",
        "    rating_encoder.fit(encoded_df[rating_col].values)\n",
        "    n_rating = len(rating_encoder.classes_)\n",
        "\n",
        "    encoded_df[\"USER\"] = user_encoder.transform(encoded_df[user_col])\n",
        "    encoded_df[\"ITEM\"] = item_encoder.transform(encoded_df[item_col])\n",
        "    encoded_df[\"RATING\"] = rating_encoder.transform(encoded_df[rating_col])\n",
        "    \n",
        "    #encoded_df.rename({rating_col: \"RATING\"}, axis=1, inplace=True)\n",
        "    \n",
        "    print(\"Number of users: \", n_users)\n",
        "    print(\"Number of items: \", n_items)\n",
        "    \n",
        "    return encoded_df, user_encoder, item_encoder, rating_encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR6Gry3eIrmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a0398d08-8cf8-44b6-c9a6-10b4e8e8b4bd"
      },
      "source": [
        "# Data Encoding\n",
        "DATA, user_encoder, item_encoder,rating_encoder = encode_user_item(df_rating, \"userid\", \"itemid\", \"rating\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of users:  40163\n",
            "Number of items:  139738\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kw7IJOGuIxYp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "739b82db-1ac8-427b-eb6c-8af819cb8f73"
      },
      "source": [
        "n_users = DATA.USER.nunique()\n",
        "n_items = DATA.ITEM.nunique()\n",
        "n_users, n_items"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40163, 139738)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35gs8ybQI_n_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9cd6e91-33b6-4240-b93c-4f4137e253aa"
      },
      "source": [
        "max_rating = DATA.RATING.max()\n",
        "min_rating = DATA.RATING.min()\n",
        "min_rating, max_rating"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei5jwnFsJDy0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def user_split (df, ratios, chrono=False):\n",
        "    \n",
        "    \"\"\"Function to split pandas DataFrame into train, validation and test (by user in chronological order)\n",
        "    \n",
        "    Params:     \n",
        "        df (pd.DataFrame): Pandas data frame to be split.\n",
        "        ratios (list of floats): list of ratios for split. The ratios have to sum to 1.\n",
        "        chrono (boolean): whether to sort in chronological order or not\n",
        "    \n",
        "    Returns: \n",
        "        list: List of pd.DataFrame split by the given specifications.\n",
        "    \"\"\"\n",
        "    seed = 42                  # Set random seed\n",
        "    samples = df.shape[0]      # Number of samples\n",
        "    col_time = \"TIMESTAMP\"\n",
        "    col_user = \"USER\"\n",
        "    \n",
        "    # Split by each group and aggregate splits together.\n",
        "    splits = []\n",
        "\n",
        "    # Sort in chronological order, the split by users\n",
        "    if chrono == True:\n",
        "        df_grouped = df.sort_values(col_time).groupby(col_user)\n",
        "    else:\n",
        "        df_grouped = df.groupby(col_user)\n",
        "\n",
        "        \n",
        "    \n",
        "    for name, group in df_grouped:\n",
        "        group_splits = random_split(df_grouped.get_group(name), ratios, shuffle=False)\n",
        "        \n",
        "        # Concatenate the list of split dataframes.\n",
        "        concat_group_splits = pd.concat(group_splits)\n",
        "        splits.append(concat_group_splits)\n",
        "    \n",
        "    # Concatenate splits for all the groups together.\n",
        "    splits_all = pd.concat(splits)\n",
        "\n",
        "    # Take split by split_index\n",
        "    splits_list = [ splits_all[splits_all[\"split_index\"] == x] for x in range(len(ratios))]\n",
        "\n",
        "    return splits_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fBPij2LJOCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_split (df, ratios, shuffle=False):\n",
        "    \n",
        "    \"\"\"Function to split pandas DataFrame into train, validation and test\n",
        "    \n",
        "    Params:     \n",
        "        df (pd.DataFrame): Pandas data frame to be split.\n",
        "        ratios (list of floats): list of ratios for split. The ratios have to sum to 1.\n",
        "    \n",
        "    Returns: \n",
        "        list: List of pd.DataFrame split by the given specifications.\n",
        "    \"\"\"\n",
        "    seed = 42                  # Set random seed\n",
        "    if shuffle == True:\n",
        "        df = df.sample(frac=1)     # Shuffle the data\n",
        "    samples = df.shape[0]      # Number of samples\n",
        "    \n",
        "    # Converts [0.7, 0.2, 0.1] to [0.7, 0.9]\n",
        "    split_ratio = np.cumsum(ratios).tolist()[:-1] # Get split index\n",
        "    \n",
        "    # Get the rounded integer split index\n",
        "    split_index = [round(x * samples) for x in split_ratio]\n",
        "    \n",
        "    # split the data\n",
        "    splits = np.split(df, split_index)\n",
        "    \n",
        "    # Add split index (this makes splitting by group more efficient).\n",
        "    for i in range(len(ratios)):\n",
        "        splits[i][\"split_index\"] = i\n",
        "\n",
        "    return splits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id0Xnsk_JT9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Splitting\n",
        "train, test = user_split(DATA, [0.8, 0.2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuoMYH97JZHM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08436ae3-30be-45f3-a8fb-835265ab39da"
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((533733, 7), (131090, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZzyFo_Iazj3",
        "colab_type": "text"
      },
      "source": [
        "## Deep Neural CF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGiiY6_wJdlt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Embedding, Flatten, Dot, Add, Lambda, Activation, Reshape, Concatenate, Dense\n",
        "from keras.regularizers import l2\n",
        "from keras.constraints import non_neg\n",
        "from keras.utils import plot_model\n",
        "from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72vMsuQNa50U",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5HlRWHeJkET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Neural_CF(n_users, n_items, n_factors):\n",
        "    \n",
        "    # Item Layer\n",
        "    item_input = Input(shape=[1], name='Item')\n",
        "    \n",
        "    # Item Embedding MF\n",
        "    item_embedding_mf = Embedding(n_items, n_factors, embeddings_regularizer=l2(1e-6),\n",
        "                                  embeddings_initializer='he_normal',\n",
        "                                  name='ItemEmbeddingMF')(item_input)\n",
        "    item_vec_mf = Flatten(name='FlattenItemMF')(item_embedding_mf)\n",
        "    \n",
        "    \n",
        "    # Item embedding MLP\n",
        "    item_embedding_mlp = Embedding(n_items, n_factors, embeddings_regularizer=l2(1e-6),\n",
        "                                embeddings_initializer='he_normal',\n",
        "                               name='ItemEmbeddingMLP')(item_input)\n",
        "    item_vec_mlp = Flatten(name='FlattenItemMLP')(item_embedding_mlp)\n",
        "    \n",
        "\n",
        "    # User Layer\n",
        "    user_input = Input(shape=[1], name='User')\n",
        "    \n",
        "    # User Embedding MF\n",
        "    user_embedding_mf = Embedding(n_users, n_factors, embeddings_regularizer=l2(1e-6), \n",
        "                                embeddings_initializer='he_normal',\n",
        "                               name='UserEmbeddingMF')(user_input)\n",
        "    user_vec_mf = Flatten(name='FlattenUserMF')(user_embedding_mf)\n",
        "    \n",
        "    # User Embedding MF\n",
        "    user_embedding_mlp = Embedding(n_users, n_factors, embeddings_regularizer=l2(1e-6),\n",
        "                               embeddings_initializer='he_normal',\n",
        "                               name='UserEmbeddingMLP')(user_input)\n",
        "    user_vec_mlp = Flatten(name='FlattenUserMLP')(user_embedding_mlp)\n",
        "    \n",
        "    # Multiply MF paths\n",
        "    DotProductMF = Dot(axes=1, name='DotProductMF')([item_vec_mf, user_vec_mf])\n",
        "    \n",
        "    # Concat MLP paths\n",
        "    ConcatMLP = Concatenate(name='ConcatMLP')([item_vec_mlp, user_vec_mlp])\n",
        "    \n",
        "    # Use Dense to learn non-linear dense representation\n",
        "    Dense_1 = Dense(50, name=\"Dense1\")(ConcatMLP)\n",
        "    Dense_2 = Dense(20, name=\"Dense2\")(Dense_1)\n",
        "\n",
        "    # Concatenate MF and MLP paths\n",
        "    Concat = Concatenate(name=\"ConcatAll\")([DotProductMF, Dense_2])\n",
        "    \n",
        "    # Use Dense to learn non-linear dense representation\n",
        "    Pred = Dense(1, name=\"Pred\")(Concat)\n",
        "    \n",
        "\n",
        "    # Item Bias\n",
        "    item_bias = Embedding(n_items, 1, embeddings_regularizer=l2(1e-5), name='ItemBias')(item_input)\n",
        "    item_bias_vec = Flatten(name='FlattenItemBiasE')(item_bias)\n",
        "\n",
        "    # User Bias\n",
        "    user_bias = Embedding(n_users, 1, embeddings_regularizer=l2(1e-5), name='UserBias')(user_input)\n",
        "    user_bias_vec = Flatten(name='FlattenUserBiasE')(user_bias)\n",
        "\n",
        "    # Pred with bias added\n",
        "    PredAddBias = Add(name=\"AddBias\")([Pred, item_bias_vec, user_bias_vec])\n",
        "    \n",
        "    \n",
        "    # Scaling for each user\n",
        "    y = Activation('sigmoid')(PredAddBias)\n",
        "    rating_output = Lambda(lambda x: x * (max_rating - min_rating) + min_rating)(y)\n",
        "    \n",
        "    # Model Creation\n",
        "    model = Model([user_input, item_input], rating_output)\n",
        "    \n",
        "    # Compile Model\n",
        "    model.compile(loss='mean_squared_error', optimizer=\"adam\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExJ1bGLHJs4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_factors = 40\n",
        "model = Neural_CF(n_users, n_items, n_factors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTsPARJeJzOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7c8e4e1-a0c9-4b53-a0ab-e900b1860314"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Item (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "User (InputLayer)               [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "ItemEmbeddingMLP (Embedding)    (None, 1, 40)        5589520     Item[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "UserEmbeddingMLP (Embedding)    (None, 1, 40)        1606520     User[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "FlattenItemMLP (Flatten)        (None, 40)           0           ItemEmbeddingMLP[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "FlattenUserMLP (Flatten)        (None, 40)           0           UserEmbeddingMLP[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "ItemEmbeddingMF (Embedding)     (None, 1, 40)        5589520     Item[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "UserEmbeddingMF (Embedding)     (None, 1, 40)        1606520     User[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "ConcatMLP (Concatenate)         (None, 80)           0           FlattenItemMLP[0][0]             \n",
            "                                                                 FlattenUserMLP[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "FlattenItemMF (Flatten)         (None, 40)           0           ItemEmbeddingMF[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "FlattenUserMF (Flatten)         (None, 40)           0           UserEmbeddingMF[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "Dense1 (Dense)                  (None, 50)           4050        ConcatMLP[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "DotProductMF (Dot)              (None, 1)            0           FlattenItemMF[0][0]              \n",
            "                                                                 FlattenUserMF[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "Dense2 (Dense)                  (None, 20)           1020        Dense1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "ConcatAll (Concatenate)         (None, 21)           0           DotProductMF[0][0]               \n",
            "                                                                 Dense2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "ItemBias (Embedding)            (None, 1, 1)         139738      Item[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "UserBias (Embedding)            (None, 1, 1)         40163       User[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "Pred (Dense)                    (None, 1)            22          ConcatAll[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "FlattenItemBiasE (Flatten)      (None, 1)            0           ItemBias[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "FlattenUserBiasE (Flatten)      (None, 1)            0           UserBias[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "AddBias (Add)                   (None, 1)            0           Pred[0][0]                       \n",
            "                                                                 FlattenItemBiasE[0][0]           \n",
            "                                                                 FlattenUserBiasE[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1)            0           AddBias[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1)            0           activation[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 14,577,073\n",
            "Trainable params: 14,577,073\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEQsBq8pbDlC",
        "colab_type": "text"
      },
      "source": [
        "### Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNneFf1AJ3QC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f9d9fa24-2c0f-4b92-e148-289cd3d7721e"
      },
      "source": [
        "%%time\n",
        "output = model.fit([train.USER, train.ITEM], train.RATING, \n",
        "                                  batch_size=128, epochs=5, verbose=1,validation_data= ([test.USER, test.ITEM], test.RATING))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "4170/4170 [==============================] - 517s 124ms/step - loss: 1.1802 - val_loss: 1.1485\n",
            "Epoch 2/5\n",
            "4170/4170 [==============================] - 502s 120ms/step - loss: 0.8772 - val_loss: 1.1980\n",
            "Epoch 3/5\n",
            "4170/4170 [==============================] - 508s 122ms/step - loss: 0.4092 - val_loss: 1.2867\n",
            "Epoch 4/5\n",
            "4170/4170 [==============================] - 508s 122ms/step - loss: 0.2437 - val_loss: 1.3069\n",
            "Epoch 5/5\n",
            "4170/4170 [==============================] - 501s 120ms/step - loss: 0.2117 - val_loss: 1.3096\n",
            "CPU times: user 1h 15min 10s, sys: 2min 31s, total: 1h 17min 42s\n",
            "Wall time: 42min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbF3NCGmKT86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import altair as alt\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "  \n",
        "        \n",
        "# Visualise the metrics from the model\n",
        "def metrics(history):\n",
        "    df = pd.DataFrame(history)\n",
        "    df.reset_index()\n",
        "    df[\"batch\"] = df.index + 1\n",
        "    df = df.melt(\"batch\", var_name=\"name\")\n",
        "    df[\"val\"] = df.name.str.startswith(\"val\")\n",
        "    df[\"type\"] = df[\"val\"]\n",
        "    df[\"metrics\"] = df[\"val\"]\n",
        "    df.loc[df.val == False, \"type\"] = \"training\"\n",
        "    df.loc[df.val == True, \"type\"] = \"validation\"\n",
        "    df.loc[df.val == False, \"metrics\"] = df.name\n",
        "    df.loc[df.val == True, \"metrics\"] = df.name.str.split(\"val_\", expand=True)[1]\n",
        "    df = df.drop([\"name\", \"val\"], axis=1)\n",
        "    \n",
        "    base = alt.Chart().encode(\n",
        "        x = \"batch:Q\",\n",
        "        y = \"value:Q\",\n",
        "        color = \"type\"\n",
        "    ).properties(width = 300, height = 300)\n",
        "\n",
        "    layers = base.mark_circle(size = 50).encode(tooltip = [\"batch\", \"value\"]) + base.mark_line()\n",
        "    chart = layers.facet(column='metrics:N', data=df).resolve_scale(y='independent')    \n",
        "    \n",
        "    return chart\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FeBEDgiKevF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "c2ca565a-44e2-42a8-9bce-a111a31fe761"
      },
      "source": [
        "metrics(output.history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "alt.FacetChart(...)"
            ],
            "text/html": [
              "\n",
              "<div id=\"altair-viz-9fd451a947bd4949b0cb97a56c3ae470\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "  (function(spec, embedOpt){\n",
              "    let outputDiv = document.currentScript.previousElementSibling;\n",
              "    if (outputDiv.id !== \"altair-viz-9fd451a947bd4949b0cb97a56c3ae470\") {\n",
              "      outputDiv = document.getElementById(\"altair-viz-9fd451a947bd4949b0cb97a56c3ae470\");\n",
              "    }\n",
              "    const paths = {\n",
              "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
              "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
              "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.8.1?noext\",\n",
              "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
              "    };\n",
              "\n",
              "    function loadScript(lib) {\n",
              "      return new Promise(function(resolve, reject) {\n",
              "        var s = document.createElement('script');\n",
              "        s.src = paths[lib];\n",
              "        s.async = true;\n",
              "        s.onload = () => resolve(paths[lib]);\n",
              "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
              "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "      });\n",
              "    }\n",
              "\n",
              "    function showError(err) {\n",
              "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
              "      throw err;\n",
              "    }\n",
              "\n",
              "    function displayChart(vegaEmbed) {\n",
              "      vegaEmbed(outputDiv, spec, embedOpt)\n",
              "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
              "    }\n",
              "\n",
              "    if(typeof define === \"function\" && define.amd) {\n",
              "      requirejs.config({paths});\n",
              "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
              "    } else if (typeof vegaEmbed === \"function\") {\n",
              "      displayChart(vegaEmbed);\n",
              "    } else {\n",
              "      loadScript(\"vega\")\n",
              "        .then(() => loadScript(\"vega-lite\"))\n",
              "        .then(() => loadScript(\"vega-embed\"))\n",
              "        .catch(showError)\n",
              "        .then(() => displayChart(vegaEmbed));\n",
              "    }\n",
              "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-1ef16ed3234f792fe361d95fcee0e182\"}, \"facet\": {\"column\": {\"type\": \"nominal\", \"field\": \"metrics\"}}, \"spec\": {\"layer\": [{\"mark\": {\"type\": \"circle\", \"size\": 50}, \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"type\"}, \"tooltip\": [{\"type\": \"quantitative\", \"field\": \"batch\"}, {\"type\": \"quantitative\", \"field\": \"value\"}], \"x\": {\"type\": \"quantitative\", \"field\": \"batch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"value\"}}, \"height\": 300, \"width\": 300}, {\"mark\": \"line\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"type\"}, \"x\": {\"type\": \"quantitative\", \"field\": \"batch\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"value\"}}, \"height\": 300, \"width\": 300}]}, \"resolve\": {\"scale\": {\"y\": \"independent\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\", \"datasets\": {\"data-1ef16ed3234f792fe361d95fcee0e182\": [{\"batch\": 1, \"value\": 1.1801695823669434, \"type\": \"training\", \"metrics\": \"loss\"}, {\"batch\": 2, \"value\": 0.877153217792511, \"type\": \"training\", \"metrics\": \"loss\"}, {\"batch\": 3, \"value\": 0.40918925404548645, \"type\": \"training\", \"metrics\": \"loss\"}, {\"batch\": 4, \"value\": 0.24366150796413422, \"type\": \"training\", \"metrics\": \"loss\"}, {\"batch\": 5, \"value\": 0.21170541644096375, \"type\": \"training\", \"metrics\": \"loss\"}, {\"batch\": 1, \"value\": 1.1484739780426025, \"type\": \"validation\", \"metrics\": \"loss\"}, {\"batch\": 2, \"value\": 1.1979619264602661, \"type\": \"validation\", \"metrics\": \"loss\"}, {\"batch\": 3, \"value\": 1.2866939306259155, \"type\": \"validation\", \"metrics\": \"loss\"}, {\"batch\": 4, \"value\": 1.3069432973861694, \"type\": \"validation\", \"metrics\": \"loss\"}, {\"batch\": 5, \"value\": 1.3095673322677612, \"type\": \"validation\", \"metrics\": \"loss\"}]}}, {\"mode\": \"vega-lite\"});\n",
              "</script>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYn-AyEJbbr-",
        "colab_type": "text"
      },
      "source": [
        "### Score the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-1iTVZdKlEE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "08765903-fa36-433b-fdf7-cbfd40475c83"
      },
      "source": [
        "score = model.evaluate([test.USER, test.ITEM], test.RATING, verbose=1)\n",
        "score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4097/4097 [==============================] - 104s 25ms/step - loss: 1.3096\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3095693588256836"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-Q_mCVcx4st",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29b825d8-8707-4c34-8885-9d937d2e4df6"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(mean_absolute_error(test.RATING, model.predict([test.USER, test.ITEM])))\n",
        "print(mean_squared_error(test.RATING, model.predict([test.USER, test.ITEM])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8488361975322627\n",
            "1.2720422777517186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phsrU2mNbqGz",
        "colab_type": "text"
      },
      "source": [
        "### Prediction & recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OGQ6954IKlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embedding(model, name):\n",
        "    embedding = model.get_layer(name = name).get_weights()[0]\n",
        "    return embedding\n",
        "\n",
        "def get_predictions(model, data):\n",
        "    \"\"\"\n",
        "    Get predictions for all user-item combinations\n",
        "    \n",
        "    Params:\n",
        "        data (pandas.DataFrame): DataFrame of entire rating data\n",
        "        model (Keras.model): Trained keras model\n",
        "        \n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame of rating predictions for each user and each item\n",
        "        \n",
        "    \"\"\"\n",
        "    # Create the crossjoin for user-item\n",
        "    user_item = user_item_crossjoin(data)\n",
        "    \n",
        "    # Score for every user-item combination\n",
        "    user_item[\"RATING_PRED\"] = model.predict([user_item.USER, user_item.ITEM])\n",
        "    \n",
        "    return user_item\n",
        "\n",
        "\n",
        "def user_item_crossjoin(df):\n",
        "    \"\"\"\n",
        "    Get cross-join of all users and items\n",
        "    \n",
        "    Args:\n",
        "        df (pd.DataFrame): Source dataframe.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Dataframe with crossjoins\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    crossjoin_list = []\n",
        "    for user in df.USER.unique():\n",
        "        for item in df.ITEM.unique():\n",
        "            crossjoin_list.append([user, item])\n",
        "\n",
        "    cross_join_df = pd.DataFrame(data=crossjoin_list, columns=[\"USER\", \"ITEM\"])\n",
        "    \n",
        "    return cross_join_df\n",
        "    \n",
        "\n",
        "def filter_by(df, filter_by_df, filter_by_cols):\n",
        "    \"\"\"From the input DataFrame (df), remove the records whose target column (filter_by_cols) values are\n",
        "    exist in the filter-by DataFrame (filter_by_df)\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Source dataframe.\n",
        "        filter_by_df (pd.DataFrame): Filter dataframe.\n",
        "        filter_by_cols (iterable of str): Filter columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Dataframe filtered by filter_by_df on filter_by_cols\n",
        "    \"\"\"\n",
        "\n",
        "    return df.loc[\n",
        "        ~df.set_index(filter_by_cols).index.isin(\n",
        "            filter_by_df.set_index(filter_by_cols).index\n",
        "        )\n",
        "    ]\n",
        "\n",
        "\n",
        "def get_top_k_items(df, col_user, col_rating, k=10):\n",
        "    \"\"\"Get the top k items for each user.\n",
        "\n",
        "    Params:\n",
        "        dataframe (pandas.DataFrame): DataFrame of rating data\n",
        "        col_user (str): column name for user\n",
        "        col_rating (str): column name for rating\n",
        "        k (int): number of items for each user\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n",
        "    \"\"\"\n",
        "    # Sort dataframe by col_user and (top k) col_rating\n",
        "    top_k_items = (\n",
        "        df.groupby(col_user, as_index=False)\n",
        "        .apply(lambda x: x.nlargest(k, col_rating))\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "    # Add ranks\n",
        "    top_k_items[\"rank\"] = top_k_items.groupby(col_user, sort=False).cumcount() + 1\n",
        "    return top_k_items\n",
        "\n",
        "\n",
        "def recommend_topk(model, data, train, k=5):\n",
        "    \n",
        "    \"\"\"\n",
        "    Params:\n",
        "        data (pandas.DataFrame): DataFrame of entire rating data\n",
        "        train (pandas.DataFrame): DataFrame of train rating data\n",
        "        k (int): number of items for each user\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame of top k items for each user, sorted by `col_user` and `rank`\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Get predictions for all user-item combination\n",
        "    all_predictions = get_predictions(model, data)\n",
        "    \n",
        "    # Handle Missing Values\n",
        "    all_predictions.fillna(0, inplace=True)\n",
        "    \n",
        "    # Filter already seen items\n",
        "    all_predictions_unseen = filter_by(all_predictions, train, [\"USER\", \"ITEM\"])\n",
        "    \n",
        "    recommend_topk_df = get_top_k_items(all_predictions_unseen, \"USER\", \"RATING_PRED\", k=5)\n",
        "    \n",
        "    return recommend_topk_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y4jDedjLsOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_embedding_mf = get_embedding(model, \"ItemEmbeddingMF\")\n",
        "user_embedding_mf = get_embedding(model, \"UserEmbeddingMF\")\n",
        "item_embedding_mlp = get_embedding(model, \"ItemEmbeddingMLP\")\n",
        "user_embedding_mlp = get_embedding(model, \"UserEmbeddingMLP\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DdGDfnpLyhW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "item_embedding = np.mean([item_embedding_mf,item_embedding_mlp], axis=0)\n",
        "user_embedding = np.mean([user_embedding_mf,user_embedding_mlp], axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wup_7aGL2Yg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "901c443f-9bc0-4664-e294-06e01d9684d7"
      },
      "source": [
        "%%time\n",
        "predictions = get_predictions(model, DATA)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12min 27s, sys: 1min 31s, total: 13min 58s\n",
            "Wall time: 10min 49s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lT3QFbMuQ-kp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "da88b1dc-8bce-482a-b0bc-5cc15a4114f4"
      },
      "source": [
        "predictions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>USER</th>\n",
              "      <th>ITEM</th>\n",
              "      <th>RATING_PRED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>113</td>\n",
              "      <td>3.928302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>224</td>\n",
              "      <td>2.791936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.913030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>335</td>\n",
              "      <td>3.921996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>446</td>\n",
              "      <td>0.940567</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   USER  ITEM  RATING_PRED\n",
              "0     0   113     3.928302\n",
              "1     0   224     2.791936\n",
              "2     0     1     2.913030\n",
              "3     0   335     3.921996\n",
              "4     0   446     0.940567"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_GnLo18RG2p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dfd809db-7dc1-4915-8d5b-2fae6f21c3fb"
      },
      "source": [
        "%%time\n",
        "# Recommendation for TopK\n",
        "ranking_topk = recommend_topk(model, DATA, train, k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12min 55s, sys: 1min 36s, total: 14min 31s\n",
            "Wall time: 11min 18s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odw7PQkeb9GM",
        "colab_type": "text"
      },
      "source": [
        "### Get Similar Items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EGIVXhRoRQlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import PIL\n",
        "\n",
        "\n",
        "def get_similar(embedding, k):\n",
        "    model_similar_items = NearestNeighbors(n_neighbors=k, algorithm=\"ball_tree\").fit(embedding)\n",
        "    distances, indices = model_similar_items.kneighbors(embedding)\n",
        "    \n",
        "    return distances, indices\n",
        "\n",
        "\n",
        "\n",
        "def show_similar(item_index, item_similar_indices, item_encoder):\n",
        "        \n",
        "    s = item_similar_indices[item_index]\n",
        "    movie_ids = item_encoder.inverse_transform(s)\n",
        "\n",
        "    images = []\n",
        "    for movie_id in movie_ids:\n",
        "        img_path = '/content/' + str(movie_id) + '.jpg'\n",
        "        images.append(mpimg.imread(img_path))\n",
        "\n",
        "    plt.figure(figsize=(20,10))\n",
        "    columns = 5\n",
        "    for i, image in enumerate(images):\n",
        "        plt.subplot(len(images) / columns + 1, columns, i + 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0BOIDy3RYPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1dbff41f-fd93-440c-c54b-b7d98671fc52"
      },
      "source": [
        "%%time\n",
        "item_distances, item_similar_indices = get_similar(item_embedding, 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7min 23s, sys: 0 ns, total: 7min 23s\n",
            "Wall time: 7min 24s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sraxgm4YRczT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "1633a52d-8fa5-4f5e-dc35-8469480dc844"
      },
      "source": [
        "item_similar_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0, 12462, 42798, 42145, 13044],\n",
              "       [    1, 24895,   597, 27778, 34143],\n",
              "       [    2,  3300, 17988, 18061, 17992],\n",
              "       ...,\n",
              "       [46616, 38831, 39759, 32239, 45504],\n",
              "       [46617,  8218, 41511, 35223, 40582],\n",
              "       [46618, 42525, 40407, 42400, 45420]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZeyWNdFRh2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "show_similar(0, item_similar_indices, item_encoder)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}